{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POS_TAGGER using HMM model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRGTn42hfNARlwDSIt0Csd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhiru-py/NLP/blob/master/POS_TAGGER_using_HMM_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyqiS02NSzOx"
      },
      "source": [
        "#======================== POS Tagger using HMM Model ======================#"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTBPbYyD4WLf",
        "outputId": "a58b13a9-b571-4d72-9233-b4a6159b9f5b"
      },
      "source": [
        "# Importing libraries\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pprint, time\n",
        " "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyNZjpiwoG_j",
        "outputId": "1b891e70-4d6a-468e-8221-3048cf480e21"
      },
      "source": [
        "#download the treebank corpus from nltk\n",
        "nltk.download('treebank')\n",
        " \n",
        "#download the universal tagset from nltk\n",
        "nltk.download('universal_tagset')\n",
        " \n",
        "# reading the Treebank tagged sentences\n",
        "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))\n",
        " \n",
        "#print the first two sentences along with tags\n",
        "print(nltk_data[:2])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n",
            "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUXcX0_M4Wjx"
      },
      "source": [
        "# As NLTK data is large in size, spliting data in small for fast computing...\n",
        "split_data = nltk_data[:500]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htyXmaJC4Woa"
      },
      "source": [
        "# split data into training and validation set in the ratio 80:20\n",
        "train_set,test_set =train_test_split(split_data,train_size=0.80,test_size=0.20,random_state = 101)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apcxM0XQ4Wsd"
      },
      "source": [
        "# create list of train and test tagged words\n",
        "train_tagged_words = [ tup for sent in train_set for tup in sent ]\n",
        "test_tagged_words = [ tup for sent in test_set for tup in sent ]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfGcS9GK4W0Q",
        "outputId": "816ae346-a3cc-4abf-f0b7-d8aba77feea5"
      },
      "source": [
        "#use set datatype to check how many unique tags and vocabs are present in training data\n",
        "tags = {tag for word,tag in train_tagged_words}\n",
        "print (tags)\n",
        " \n",
        "# check total words in vocabulary\n",
        "vocab = {word for word,tag in train_tagged_words}"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'PRT', 'CONJ', 'ADJ', 'X', 'PRON', 'ADP', 'NOUN', '.', 'VERB', 'ADV', 'NUM', 'DET'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhgqAQ0O4W4M",
        "outputId": "86abe085-7120-48d8-bca8-939eba34c837"
      },
      "source": [
        "# compute Emission Probability\n",
        "# How likely a word will be Noun, Verb, Adjective, Adverb and all.\n",
        "\n",
        "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
        "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
        "    count_tag = len(tag_list)             #total number of times the passed tag occurred in train_bag\n",
        "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
        "\n",
        "#now calculate the total number of times the passed word occurred as the passed tag.\n",
        "    count_w_given_tag = len(w_given_tag_list)\n",
        "    return (count_w_given_tag, count_tag)\n",
        "\n",
        "# Let's see how this Emission Probability does work !\n",
        "word = \"sales\"\n",
        "tag = \"NOUN\"\n",
        "train_bag = train_tagged_words\n",
        "\n",
        "emission_prob = word_given_tag(word, tag, train_bag)\n",
        "emission_prob"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 2926)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFjwZ7oz5FVd",
        "outputId": "d3c49840-3459-4a1b-bb2a-f4faf4738d7b"
      },
      "source": [
        "# compute  Transition Probability\n",
        "# How likely a sequence followed by other sequences\n",
        " \n",
        "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
        "    tags = [pair[1] for pair in train_bag]\n",
        "    count_t1 = len([t for t in tags if t==t1])\n",
        "    count_t2_t1 = 0\n",
        "    for index in range(len(tags)-1):\n",
        "        if tags[index]==t1 and tags[index+1] == t2:\n",
        "            count_t2_t1 += 1\n",
        "    return (count_t2_t1, count_t1)\n",
        "\n",
        "\n",
        "# Let's see how transition probability does work !\n",
        "\n",
        "t2 = \"ADJ\"\n",
        "t1 = \"NOUN\"\n",
        "train_bag = train_tagged_words\n",
        "\n",
        "transition_prob = t2_given_t1(t2, t1, train_bag)\n",
        "transition_prob"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38, 2926)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SocBsDIG5Ifl",
        "outputId": "f08ee73c-f80c-48a7-9453-448e1f0edc67"
      },
      "source": [
        "# creating t x t transition matrix of tags, t= no of tags\n",
        "# Matrix(i, j) represents P(jth tag after the ith tag)\n",
        " \n",
        "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
        "\n",
        "for i, t1 in enumerate(tags):\n",
        "    for j, t2 in enumerate(tags): \n",
        "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]\n",
        " \n",
        "print(tags_matrix)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.06862745 0.01633987 0.0130719  0.0130719\n",
            "  0.2777778  0.05228758 0.35947713 0.00980392 0.04901961 0.14052288]\n",
            " [0.         0.         0.12135922 0.         0.03883495 0.03398058\n",
            "  0.43203884 0.01456311 0.17475729 0.04368932 0.02427184 0.11650486]\n",
            " [0.00764526 0.01681957 0.06880734 0.01529052 0.00152905 0.09480122\n",
            "  0.6788991  0.06269113 0.01070336 0.00764526 0.02752294 0.00764526]\n",
            " [0.16666667 0.0046729  0.02180685 0.09345794 0.04517134 0.17133956\n",
            "  0.05919003 0.16666667 0.19314642 0.02647975 0.00155763 0.04984424]\n",
            " [0.01793722 0.00896861 0.06278027 0.11659193 0.00896861 0.03139013\n",
            "  0.24663678 0.01345291 0.4394619  0.03139013 0.02242152 0.        ]\n",
            " [0.00096805 0.         0.09777348 0.03291385 0.04356244 0.02129719\n",
            "  0.34365925 0.03969022 0.00580833 0.01548887 0.07938045 0.3194579 ]\n",
            " [0.0430622  0.04203691 0.01298701 0.02289815 0.00615174 0.17737526\n",
            "  0.2740943  0.22795625 0.1582365  0.01742994 0.00649351 0.0112782 ]\n",
            " [0.00093545 0.04677268 0.05238541 0.01683817 0.05799813 0.09167446\n",
            "  0.22731525 0.05332086 0.0869972  0.05799813 0.09073901 0.2160898 ]\n",
            " [0.03960396 0.00380807 0.05483625 0.2239147  0.03579589 0.10053313\n",
            "  0.10586444 0.02894136 0.18583396 0.08910891 0.01904036 0.11271896]\n",
            " [0.01529052 0.01223242 0.14067279 0.04892967 0.01223242 0.13149847\n",
            "  0.02752294 0.11009175 0.3058104  0.08562691 0.04281345 0.06727829]\n",
            " [0.01098901 0.01923077 0.03296703 0.21428572 0.         0.04945055\n",
            "  0.37637362 0.10439561 0.01373626 0.00274725 0.17307693 0.00274725]\n",
            " [0.00114416 0.00114416 0.2402746  0.0389016  0.00343249 0.01258581\n",
            "  0.6052632  0.02517162 0.03089245 0.01258581 0.0228833  0.00572082]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "AM9A3Glj5Kzz",
        "outputId": "7c3915df-0cb2-4b1a-f7da-497fbb8c644e"
      },
      "source": [
        "# convert the matrix to a data frame for better readability\n",
        "# the table is same as the transition table shown in section 3 of article\n",
        "\n",
        "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))\n",
        "display(tags_df)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRT</th>\n",
              "      <th>CONJ</th>\n",
              "      <th>ADJ</th>\n",
              "      <th>X</th>\n",
              "      <th>PRON</th>\n",
              "      <th>ADP</th>\n",
              "      <th>NOUN</th>\n",
              "      <th>.</th>\n",
              "      <th>VERB</th>\n",
              "      <th>ADV</th>\n",
              "      <th>NUM</th>\n",
              "      <th>DET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PRT</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.068627</td>\n",
              "      <td>0.016340</td>\n",
              "      <td>0.013072</td>\n",
              "      <td>0.013072</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.052288</td>\n",
              "      <td>0.359477</td>\n",
              "      <td>0.009804</td>\n",
              "      <td>0.049020</td>\n",
              "      <td>0.140523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CONJ</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.121359</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038835</td>\n",
              "      <td>0.033981</td>\n",
              "      <td>0.432039</td>\n",
              "      <td>0.014563</td>\n",
              "      <td>0.174757</td>\n",
              "      <td>0.043689</td>\n",
              "      <td>0.024272</td>\n",
              "      <td>0.116505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADJ</th>\n",
              "      <td>0.007645</td>\n",
              "      <td>0.016820</td>\n",
              "      <td>0.068807</td>\n",
              "      <td>0.015291</td>\n",
              "      <td>0.001529</td>\n",
              "      <td>0.094801</td>\n",
              "      <td>0.678899</td>\n",
              "      <td>0.062691</td>\n",
              "      <td>0.010703</td>\n",
              "      <td>0.007645</td>\n",
              "      <td>0.027523</td>\n",
              "      <td>0.007645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.004673</td>\n",
              "      <td>0.021807</td>\n",
              "      <td>0.093458</td>\n",
              "      <td>0.045171</td>\n",
              "      <td>0.171340</td>\n",
              "      <td>0.059190</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.193146</td>\n",
              "      <td>0.026480</td>\n",
              "      <td>0.001558</td>\n",
              "      <td>0.049844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRON</th>\n",
              "      <td>0.017937</td>\n",
              "      <td>0.008969</td>\n",
              "      <td>0.062780</td>\n",
              "      <td>0.116592</td>\n",
              "      <td>0.008969</td>\n",
              "      <td>0.031390</td>\n",
              "      <td>0.246637</td>\n",
              "      <td>0.013453</td>\n",
              "      <td>0.439462</td>\n",
              "      <td>0.031390</td>\n",
              "      <td>0.022422</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADP</th>\n",
              "      <td>0.000968</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.097773</td>\n",
              "      <td>0.032914</td>\n",
              "      <td>0.043562</td>\n",
              "      <td>0.021297</td>\n",
              "      <td>0.343659</td>\n",
              "      <td>0.039690</td>\n",
              "      <td>0.005808</td>\n",
              "      <td>0.015489</td>\n",
              "      <td>0.079380</td>\n",
              "      <td>0.319458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NOUN</th>\n",
              "      <td>0.043062</td>\n",
              "      <td>0.042037</td>\n",
              "      <td>0.012987</td>\n",
              "      <td>0.022898</td>\n",
              "      <td>0.006152</td>\n",
              "      <td>0.177375</td>\n",
              "      <td>0.274094</td>\n",
              "      <td>0.227956</td>\n",
              "      <td>0.158237</td>\n",
              "      <td>0.017430</td>\n",
              "      <td>0.006494</td>\n",
              "      <td>0.011278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>.</th>\n",
              "      <td>0.000935</td>\n",
              "      <td>0.046773</td>\n",
              "      <td>0.052385</td>\n",
              "      <td>0.016838</td>\n",
              "      <td>0.057998</td>\n",
              "      <td>0.091674</td>\n",
              "      <td>0.227315</td>\n",
              "      <td>0.053321</td>\n",
              "      <td>0.086997</td>\n",
              "      <td>0.057998</td>\n",
              "      <td>0.090739</td>\n",
              "      <td>0.216090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VERB</th>\n",
              "      <td>0.039604</td>\n",
              "      <td>0.003808</td>\n",
              "      <td>0.054836</td>\n",
              "      <td>0.223915</td>\n",
              "      <td>0.035796</td>\n",
              "      <td>0.100533</td>\n",
              "      <td>0.105864</td>\n",
              "      <td>0.028941</td>\n",
              "      <td>0.185834</td>\n",
              "      <td>0.089109</td>\n",
              "      <td>0.019040</td>\n",
              "      <td>0.112719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADV</th>\n",
              "      <td>0.015291</td>\n",
              "      <td>0.012232</td>\n",
              "      <td>0.140673</td>\n",
              "      <td>0.048930</td>\n",
              "      <td>0.012232</td>\n",
              "      <td>0.131498</td>\n",
              "      <td>0.027523</td>\n",
              "      <td>0.110092</td>\n",
              "      <td>0.305810</td>\n",
              "      <td>0.085627</td>\n",
              "      <td>0.042813</td>\n",
              "      <td>0.067278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NUM</th>\n",
              "      <td>0.010989</td>\n",
              "      <td>0.019231</td>\n",
              "      <td>0.032967</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.049451</td>\n",
              "      <td>0.376374</td>\n",
              "      <td>0.104396</td>\n",
              "      <td>0.013736</td>\n",
              "      <td>0.002747</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>0.002747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DET</th>\n",
              "      <td>0.001144</td>\n",
              "      <td>0.001144</td>\n",
              "      <td>0.240275</td>\n",
              "      <td>0.038902</td>\n",
              "      <td>0.003432</td>\n",
              "      <td>0.012586</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.025172</td>\n",
              "      <td>0.030892</td>\n",
              "      <td>0.012586</td>\n",
              "      <td>0.022883</td>\n",
              "      <td>0.005721</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           PRT      CONJ       ADJ  ...       ADV       NUM       DET\n",
              "PRT   0.000000  0.000000  0.068627  ...  0.009804  0.049020  0.140523\n",
              "CONJ  0.000000  0.000000  0.121359  ...  0.043689  0.024272  0.116505\n",
              "ADJ   0.007645  0.016820  0.068807  ...  0.007645  0.027523  0.007645\n",
              "X     0.166667  0.004673  0.021807  ...  0.026480  0.001558  0.049844\n",
              "PRON  0.017937  0.008969  0.062780  ...  0.031390  0.022422  0.000000\n",
              "ADP   0.000968  0.000000  0.097773  ...  0.015489  0.079380  0.319458\n",
              "NOUN  0.043062  0.042037  0.012987  ...  0.017430  0.006494  0.011278\n",
              ".     0.000935  0.046773  0.052385  ...  0.057998  0.090739  0.216090\n",
              "VERB  0.039604  0.003808  0.054836  ...  0.089109  0.019040  0.112719\n",
              "ADV   0.015291  0.012232  0.140673  ...  0.085627  0.042813  0.067278\n",
              "NUM   0.010989  0.019231  0.032967  ...  0.002747  0.173077  0.002747\n",
              "DET   0.001144  0.001144  0.240275  ...  0.012586  0.022883  0.005721\n",
              "\n",
              "[12 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4Vl_DCe53QR"
      },
      "source": [
        "def Viterbi(words, train_bag = train_tagged_words):\n",
        "    state = []\n",
        "    T = list(set([pair[1] for pair in train_bag]))\n",
        "     \n",
        "    for key, word in enumerate(words):\n",
        "        #initialise list of probability column for a given observation\n",
        "        p = [] \n",
        "        for tag in T:\n",
        "            if key == 0:\n",
        "                transition_p = tags_df.loc['.', tag]\n",
        "            else:\n",
        "                transition_p = tags_df.loc[state[-1], tag]\n",
        "                 \n",
        "            # compute emission and state probabilities\n",
        "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
        "            state_probability = emission_p * transition_p    \n",
        "            p.append(state_probability)\n",
        "             \n",
        "        pmax = max(p)\n",
        "        # getting state for which probability is maximum\n",
        "        state_max = T[p.index(pmax)] \n",
        "        state.append(state_max)\n",
        "    return list(zip(words, state))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChoJokZt55jh",
        "outputId": "553ac46b-c611-47da-ae96-cf067ab4a5c6"
      },
      "source": [
        "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
        "random.seed(500)      #define a random seed to get same sentences when run multiple times\n",
        " \n",
        "# choose random 10 numbers\n",
        "rndom = [random.randint(1,len(test_set)) for x in range(10)]\n",
        " \n",
        "# list of 10 sents on which we test the model\n",
        "test_sentences = [test_set[i] for i in rndom]\n",
        " \n",
        "# list of tagged words\n",
        "test_tagged_words = [tup for sent in test_sentences for tup in sent]\n",
        " \n",
        "# list of untagged words\n",
        "test_untagged_words = [tup[0] for sent in test_sentences for tup in sent]\n",
        "print (test_untagged_words)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'new', 'company', 'said', '0', 'it', 'believes', '0', 'there', 'are', 'fewer', 'than', '100', 'potential', 'customers', 'for', 'supercomputers', 'priced', '*', 'between', '$', '15', 'million', 'and', '$', '30', 'million', '*U*', '--', 'presumably', 'the', 'Cray-3', 'price', 'range', '.', 'The', 'move', 'leaves', 'United', 'Illuminating', 'Co.', 'and', 'Northeast', 'Utilities', 'as', 'the', 'remaining', 'outside', 'bidders', 'for', 'PS', 'of', 'New', 'Hampshire', ',', 'which', '*T*-1', 'also', 'has', 'proposed', 'an', 'internal', 'reorganization', 'plan', 'in', 'Chapter', '11', 'bankruptcy', 'proceedings', 'under', 'which', 'it', 'would', 'remain', 'an', 'independent', 'company', '*T*-2', '.', 'The', 'commission', 'is', 'expected', '*-1', 'to', 'rule', 'on', 'the', 'Braidwood', '2', 'case', 'by', 'year', 'end', '.', 'The', 'new', 'company', 'said', '0', 'it', 'believes', '0', 'there', 'are', 'fewer', 'than', '100', 'potential', 'customers', 'for', 'supercomputers', 'priced', '*', 'between', '$', '15', 'million', 'and', '$', '30', 'million', '*U*', '--', 'presumably', 'the', 'Cray-3', 'price', 'range', '.', 'He', 'will', 'continue', '*-1', 'to', 'report', 'to', 'Donald', 'Pardus', ',', 'president', 'and', 'chief', 'executive', 'officer', '.', 'Mr.', 'Spoon', 'said', '0', 'the', 'plan', 'is', 'not', 'an', 'attempt', '*', 'to', 'shore', 'up', 'a', 'decline', 'in', 'ad', 'pages', 'in', 'the', 'first', 'nine', 'months', 'of', '1989', ';', 'Newsweek', \"'s\", 'ad', 'pages', 'totaled', '1,620', ',', 'a', 'drop', 'of', '3.2', '%', 'from', 'last', 'year', ',', 'according', 'to', 'Publishers', 'Information', 'Bureau', '.', 'When', 'it', \"'s\", 'time', 'for', 'their', 'biannual', 'powwow', '*T*-1', ',', 'the', 'nation', \"'s\", 'manufacturing', 'titans', 'typically', 'jet', 'off', 'to', 'the', 'sunny', 'confines', 'of', 'resort', 'towns', 'like', 'Boca', 'Raton', 'and', 'Hot', 'Springs', '.', 'Documents', 'filed', '*', 'with', 'the', 'Securities', 'and', 'Exchange', 'Commission', 'on', 'the', 'pending', 'spinoff', 'disclosed', 'that', 'Cray', 'Research', 'Inc.', 'will', 'withdraw', 'the', 'almost', '$', '100', 'million', '*U*', 'in', 'financing', '0', 'it', 'is', 'providing', 'the', 'new', 'firm', '*T*-1', 'if', 'Mr.', 'Cray', 'leaves', 'or', 'if', 'the', 'product-design', 'project', '0', 'he', 'heads', '*T*-2', 'is', 'scrapped', '*-18', '.', 'For', '1988', ',', 'Commonwealth', 'Edison', 'reported', 'earnings', 'of', '$', '737.5', 'million', '*U*', ',', 'or', '$', '3.01', '*U*', 'a', 'share', '.', 'The', 'Treasury', 'said', '0', 'the', 'U.S.', 'will', 'default', 'on', 'Nov.', '9', 'if', 'Congress', 'does', \"n't\", 'act', 'by', 'then', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMz6zdIC5_al",
        "outputId": "7a4d0efc-68fd-4463-dbd4-03e89c2b59ac"
      },
      "source": [
        "#Here We will only test 10 sentences to check the accuracy\n",
        "#as testing the whole training set takes huge amount of time\n",
        "start = time.time()\n",
        "tagged_seq = Viterbi(test_untagged_words)\n",
        "end = time.time()\n",
        "difference = end-start\n",
        " \n",
        "print(\"Time taken in seconds: \", difference)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken in seconds:  5.411680698394775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5k0V5b7t9aw",
        "outputId": "29940760-db5f-467b-d857-2acf7d386de0"
      },
      "source": [
        " # accuracy\n",
        "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
        " \n",
        "accuracy = len(check)/len(tagged_seq)\n",
        "print('Viterbi Algorithm Accuracy: ',accuracy*100)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Viterbi Algorithm Accuracy:  83.07210031347962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7nVdFPT6RJu",
        "outputId": "2ad66c78-890a-4906-c453-48c38890b5e2"
      },
      "source": [
        "#Code to test all the test sentences\n",
        "\n",
        "test_tagged_words = [tup for sent in test_set for tup in sent]\n",
        "test_untagged_words = [tup[0] for sent in test_set for tup in sent]\n",
        "print (test_untagged_words)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['``', 'The', 'morbidity', 'rate', 'is', 'a', 'striking', 'finding', 'among', 'those', 'of', 'us', 'who', '*T*-5', 'study', 'asbestos-related', 'diseases', ',', \"''\", 'said', '*T*-1', 'Dr.', 'Talcott', '.', 'Coincident', 'with', 'the', 'talks', ',', 'the', 'State', 'Department', 'said', '0', 'it', 'has', 'permitted', 'a', 'Soviet', 'bank', 'to', 'open', 'a', 'New', 'York', 'branch', '.', 'Newsweek', 'said', '0', 'it', 'will', 'introduce', 'the', 'Circulation', 'Credit', 'Plan', ',', 'which', '*T*-1', 'awards', 'space', 'credits', '*ICH*-2', 'to', 'advertisers', 'on', '``', 'renewal', 'advertising', '.', \"''\", 'The', 'asbestos', 'fiber', ',', 'crocidolite', ',', 'is', 'unusually', 'resilient', 'once', 'it', 'enters', 'the', 'lungs', ',', 'with', 'even', 'brief', 'exposures', 'to', 'it', 'causing', 'symptoms', 'that', '*T*-1', 'show', 'up', 'decades', 'later', ',', 'researchers', 'said', '0', '*T*-2', '.', 'Last', 'year', 'Commonwealth', 'Edison', 'had', '*-1', 'to', 'refund', '$', '72.7', 'million', '*U*', 'for', 'poor', 'performance', 'of', 'its', 'LaSalle', 'I', 'nuclear', 'plant', '.', '``', 'I', \"'m\", 'very', 'alarmed', '*-2', 'to', 'see', 'these', 'rich', 'valuations', ',', \"''\", 'says', '*T*-1', 'Smith', 'Barney', \"'s\", 'Mr.', 'Porter', '.', 'It', 'has', 'no', 'bearing', 'on', 'our', 'work', 'force', 'today', '.', 'Mr.', 'Stevens', 'was', 'executive', 'vice', 'president', 'of', 'this', 'electric-utility', 'holding', 'company', '.', 'After', 'the', 'race', ',', 'Fortune', '500', 'executives', 'drooled', 'like', 'schoolboys', 'over', 'the', 'cars', 'and', 'drivers', '.', 'Only', '19', '%', 'of', 'the', 'purchasing', 'managers', 'reported', 'better', 'export', 'orders', 'in', 'October', ',', 'down', 'from', '27', '%', 'in', 'September', '.', 'It', 'said', '0', 'the', 'man', ',', 'whom', 'it', 'did', 'not', 'name', '*T*-63', ',', 'had', 'been', 'found', '*-1', 'to', 'have', 'the', 'disease', 'after', 'hospital', 'tests', '.', 'In', 'Malaysia', ',', 'Siti', 'Zaharah', 'Sulaiman', ',', 'a', 'deputy', 'minister', 'in', 'the', 'prime', 'minister', \"'s\", 'office', ',', 'launched', 'a', '``', 'No-Smoking', 'Week', \"''\", 'at', 'the', 'Mara', 'Institute', 'of', 'Technology', 'near', 'Kuala', 'Lumpur', 'and', 'urged', 'other', 'schools', '*-1', 'to', 'ban', 'on-campus', 'smoking', '.', 'From', 'January', 'to', 'October', ',', 'the', 'nation', \"'s\", 'accumulated', 'exports', 'increased', '4', '%', 'from', 'the', 'same', 'period', 'last', 'year', 'to', '$', '50.45', 'billion', '*U*', '.', 'They', 'argue', 'that', 'U.S.', 'investors', 'often', 'can', 'buy', 'American', 'depositary', 'receipts', 'on', 'the', 'big', 'stocks', 'in', 'many', 'funds', ';', 'these', 'so-called', 'ADRs', 'represent', 'shares', 'of', 'foreign', 'companies', 'traded', '*', 'in', 'the', 'U.S.', '.', 'Clark', 'J.', 'Vitulli', 'was', 'named', '*-12', 'senior', 'vice', 'president', '*RNR*-1', 'and', 'general', 'manager', '*RNR*-1', 'of', 'this', 'U.S.', 'sales', 'and', 'marketing', 'arm', 'of', 'Japanese', 'auto', 'maker', 'Mazda', 'Motor', 'Corp', '.', 'The', 'average', 'maturity', 'for', 'funds', 'open', 'only', 'to', 'institutions', ',', 'considered', 'by', 'some', '*', 'to', 'be', 'a', 'stronger', 'indicator', 'because', 'those', 'managers', 'watch', 'the', 'market', 'closely', ',', 'reached', 'a', 'high', 'point', 'for', 'the', 'year', '--', '33', 'days', '.', 'But', 'the', 'Soviets', 'might', 'still', 'face', 'legal', 'obstacles', 'to', '*', 'raising', 'money', 'in', 'the', 'U.S.', 'until', 'they', 'settle', 'hundreds', 'of', 'millions', 'of', 'dollars', 'in', 'additional', 'debt', 'still', 'outstanding', 'from', 'the', 'World', 'War', 'II', 'lend-lease', 'program', '.', '``', 'Argentina', 'aspires', '*-2', 'to', 'reach', 'a', 'reduction', 'of', '50', '%', 'in', 'the', 'value', 'of', 'its', 'external', 'debt', ',', \"''\", 'Mr.', 'Rapanelli', 'said', '*T*-1', 'through', 'his', 'spokesman', ',', 'Miguel', 'Alurralde', '.', 'The', 'announcement', 'follows', 'a', 'sharper', '$', '2.2', 'billion', '*U*', 'decline', 'in', 'the', 'country', \"'s\", 'foreign', 'reserves', 'in', 'September', 'to', '$', '86.12', 'billion', '*U*', '.', 'Although', '*-2', 'set', '*-1', 'in', 'Japan', ',', 'the', 'novel', \"'s\", 'texture', 'is', 'almost', 'entirely', 'Western', ',', 'especially', 'American', '.', 'Dr.', 'Talcott', 'led', 'a', 'team', 'of', 'researchers', 'from', 'the', 'National', 'Cancer', 'Institute', 'and', 'the', 'medical', 'schools', 'of', 'Harvard', 'University', 'and', 'Boston', 'University', '.', 'He', 'was', 'previously', 'vice', 'president', '.', 'Analysts', 'said', '0', 'Mr.', 'Stronach', 'wants', '*-1', 'to', 'resume', 'a', 'more', 'influential', 'role', 'in', '*', 'running', 'the', 'company', '.', 'That', 'year', 'the', 'Apple', 'II', ',', 'Commodore', 'Pet', 'and', 'Tandy', 'TRS-80', 'came', 'to', 'market', '.', '-LRB-', 'During', 'its', 'centennial', 'year', ',', 'The', 'Wall', 'Street', 'Journal', 'will', 'report', 'events', 'of', 'the', 'past', 'century', 'that', '*T*-30', 'stand', 'as', 'milestones', 'of', 'American', 'business', 'history', '.', '-RRB-', '``', 'I', 'draw', 'a', 'blank', '.', \"''\", 'But', 'other', 'than', 'the', 'fact', 'that', 'besuboru', 'is', 'played', '*-1', 'with', 'a', 'ball', 'and', 'a', 'bat', ',', 'it', \"'s\", 'unrecognizable', ':', 'Fans', 'politely', 'return', 'foul', 'balls', 'to', 'stadium', 'ushers', ';', 'the', 'strike', 'zone', 'expands', 'depending', 'on', 'the', 'size', 'of', 'the', 'hitter', ';', 'ties', 'are', 'permitted', '*-2', '--', 'even', 'welcomed', '*-2', '--', 'since', 'they', 'honorably', 'sidestep', 'the', 'shame', 'of', 'defeat', ';', 'players', 'must', 'abide', 'by', 'strict', 'rules', 'of', 'conduct', 'even', 'in', 'their', 'personal', 'lives', '--', 'players', 'for', 'the', 'Tokyo', 'Giants', ',', 'for', 'example', ',', 'must', 'always', 'wear', 'ties', 'when', 'on', 'the', 'road', '.', 'It', \"'s\", 'the', 'latest', 'investment', 'craze', 'sweeping', 'Wall', 'Street', ':', 'a', 'rash', 'of', 'new', 'closed-end', 'country', 'funds', ',', 'those', 'publicly', 'traded', 'portfolios', 'that', '*T*-37', 'invest', 'in', 'stocks', 'of', 'a', 'single', 'foreign', 'country', '.', 'The', 'Treasury', 'said', '0', 'the', 'U.S.', 'will', 'default', 'on', 'Nov.', '9', 'if', 'Congress', 'does', \"n't\", 'act', 'by', 'then', '.', 'Financial', 'planners', 'often', 'urge', 'investors', '*-1', 'to', 'diversify', 'and', 'to', 'hold', 'a', 'smattering', 'of', 'international', 'securities', '.', 'The', 'percentage', 'of', 'lung', 'cancer', 'deaths', 'among', 'the', 'workers', 'at', 'the', 'West', 'Groton', ',', 'Mass.', ',', 'paper', 'factory', 'appears', '*-1', 'to', 'be', 'the', 'highest', 'for', 'any', 'asbestos', 'workers', 'studied', '*', 'in', 'Western', 'industrialized', 'countries', ',', 'he', 'said', '0', '*T*-2', '.', 'Faulding', 'said', '0', 'it', 'owns', '33', '%', 'of', 'Moleculon', \"'s\", 'voting', 'stock', 'and', 'has', 'an', 'agreement', '*', 'to', 'acquire', 'an', 'additional', '19', '%', '.', 'The', 'declaration', 'by', 'Economy', 'Minister', 'Nestor', 'Rapanelli', 'is', 'believed', '*-1', 'to', 'be', 'the', 'first', 'time', '0', 'such', 'an', 'action', 'has', 'been', 'called', 'for', '*-3', 'by', 'an', 'Argentine', 'official', 'of', 'such', 'stature', '*T*-2', '.', 'He', 'will', 'continue', '*-1', 'to', 'report', 'to', 'Donald', 'Pardus', ',', 'president', 'and', 'chief', 'executive', 'officer', '.', '``', 'It', 'has', '*-2', 'to', 'be', 'considered', '*-21', 'as', 'an', 'additional', 'risk', 'for', 'the', 'investor', ',', \"''\", 'said', '*T*-1', 'Gary', 'P.', 'Smaby', 'of', 'Smaby', 'Group', 'Inc.', ',', 'Minneapolis', '.', 'Magna', 'International', 'Inc.', \"'s\", 'chief', 'financial', 'officer', ',', 'James', 'McAlpine', ',', 'resigned', 'and', 'its', 'chairman', ',', 'Frank', 'Stronach', ',', 'is', 'stepping', 'in', '*-1', 'to', 'help', 'turn', 'the', 'automotive-parts', 'manufacturer', 'around', ',', 'the', 'company', 'said', '0', '*T*-2', '.', '``', 'But', 'you', 'have', '*-1', 'to', 'recognize', 'that', 'these', 'events', 'took', 'place', '35', 'years', 'ago', '.', '``', 'Wa', \"''\", 'is', 'Japanese', 'for', '``', 'team', 'spirit', \"''\", 'and', 'Japanese', 'ballplayers', 'have', 'miles', 'and', 'miles', 'of', 'it', '.', 'It', '*EXP*-1', \"'s\", 'a', 'shame', '0', 'their', 'meeting', 'never', 'took', 'place', '.', '``', 'What', 'this', 'tells', 'us', '*T*-28', 'is', 'that', 'U.S.', 'trade', 'law', 'is', 'working', ',', \"''\", 'he', 'said', '*T*-1', '.', 'The', 'rest', 'went', 'to', 'investors', 'from', 'France', 'and', 'Hong', 'Kong', '.', 'They', 'read', 'Mickey', 'Spillane', 'and', 'talk', 'about', 'Groucho', 'and', 'Harpo', '.', 'Spending', 'on', 'private', ',', 'nonresidential', 'construction', 'was', 'off', '2.6', '%', 'to', 'an', 'annual', 'rate', 'of', '$', '99.1', 'billion', '*U*', 'with', 'no', 'sector', 'showing', 'strength', '.', 'South', 'Korea', 'registered', 'a', 'trade', 'deficit', 'of', '$', '101', 'million', '*U*', 'in', 'October', ',', '*', 'reflecting', 'the', 'country', \"'s\", 'economic', 'sluggishness', ',', 'according', 'to', 'government', 'figures', 'released', '*', 'Wednesday', '.', 'Italian', 'chemical', 'giant', 'Montedison', 'S.p.A.', ',', 'through', 'its', 'Montedison', 'Acquisition', 'N.V.', 'indirect', 'unit', ',', 'began', 'its', '$', '37-a-share', '*U*', 'tender', 'offer', 'for', 'all', 'the', 'common', 'shares', 'outstanding', 'of', 'Erbamont', 'N.V.', ',', 'a', 'maker', 'of', 'pharmaceuticals', 'incorporated', '*', 'in', 'the', 'Netherlands', '.', 'Alan', 'Spoon', ',', 'recently', 'named', '*', 'Newsweek', 'president', ',', 'said', '0', 'Newsweek', \"'s\", 'ad', 'rates', 'would', 'increase', '5', '%', 'in', 'January', '.', 'But', 'Sony', 'ultimately', 'took', 'a', 'lesson', 'from', 'the', 'American', 'management', 'books', 'and', 'fired', 'Mr.', 'Katzenstein', ',', 'after', 'he', 'committed', 'the', 'social', 'crime', 'of', '*', 'making', 'an', 'appointment', '*', 'to', 'see', 'the', 'venerable', 'Akio', 'Morita', ',', 'founder', 'of', 'Sony', '.', 'The', 'new', ',', 'seven-year', 'funds', '--', 'one', 'offering', 'a', 'fixed-rate', 'return', 'and', 'the', 'other', 'with', 'a', 'floating-rate', 'return', 'linked', '*', 'to', 'the', 'London', 'interbank', 'offered', 'rate', '--', 'offer', 'two', 'key', 'advantages', 'to', 'Japanese', 'investors', '.', 'Mr.', 'Stronach', ',', 'founder', 'and', 'controlling', 'shareholder', 'of', 'Magna', ',', 'resigned', 'as', 'chief', 'executive', 'officer', 'last', 'year', '*-1', 'to', 'seek', ',', 'unsuccessfully', ',', 'a', 'seat', 'in', 'Canada', \"'s\", 'Parliament', '.', 'For', '1988', ',', 'Commonwealth', 'Edison', 'reported', 'earnings', 'of', '$', '737.5', 'million', '*U*', ',', 'or', '$', '3.01', '*U*', 'a', 'share', '.', 'Dodge', 'reported', 'an', '8', '%', 'increase', 'in', 'construction', 'contracts', 'awarded', '*', 'in', 'September', '.', 'PS', 'of', 'New', 'Hampshire', 'shares', 'closed', 'yesterday', 'at', '$', '3.75', '*U*', ',', 'off', '25', 'cents', ',', 'in', 'New', 'York', 'Stock', 'Exchange', 'composite', 'trading', '.', 'Those', 'countries', '--', 'including', 'Japan', ',', 'Italy', ',', 'Canada', ',', 'Greece', 'and', 'Spain', '--', 'are', 'still', 'of', 'some', 'concern', 'to', 'the', 'U.S.', 'but', 'are', 'deemed', '*-1', 'to', 'pose', 'less-serious', 'problems', 'for', 'American', 'patent', 'and', 'copyright', 'owners', 'than', 'those', 'on', 'the', '``', 'priority', \"''\", 'list', '.', 'Rudolph', 'Agnew', ',', '55', 'years', 'old', 'and', 'former', 'chairman', 'of', 'Consolidated', 'Gold', 'Fields', 'PLC', ',', 'was', 'named', '*-1', 'a', 'nonexecutive', 'director', 'of', 'this', 'British', 'industrial', 'conglomerate', '.', 'Meanwhile', ',', 'the', 'National', 'Association', 'of', 'Purchasing', 'Management', 'said', '0', 'its', 'latest', 'survey', 'indicated', 'that', 'the', 'manufacturing', 'economy', 'contracted', 'in', 'October', 'for', 'the', 'sixth', 'consecutive', 'month', '.', '*', 'Judging', 'from', 'the', 'Americana', 'in', 'Haruki', 'Murakami', \"'s\", '``', 'A', 'Wild', 'Sheep', 'Chase', \"''\", '-LRB-', 'Kodansha', ',', '320', 'pages', ',', '$', '18.95', '*U*', '-RRB-', ',', 'baby', 'boomers', 'on', 'both', 'sides', 'of', 'the', 'Pacific', 'have', 'a', 'lot', 'in', 'common', '.', 'The', 'new', 'ad', 'plan', 'from', 'Newsweek', ',', 'a', 'unit', 'of', 'the', 'Washington', 'Post', 'Co.', ',', 'is', 'the', 'second', 'incentive', 'plan', '0', 'the', 'magazine', 'has', 'offered', 'advertisers', '*T*-1', 'in', 'three', 'years', '.', 'She', 'said', '0', 'there', 'is', '``', 'growing', 'realization', '*ICH*-1', \"''\", 'around', 'the', 'world', 'that', 'denial', 'of', 'intellectual-property', 'rights', 'harms', 'all', 'trading', 'nations', ',', 'and', 'particularly', 'the', '``', 'creativity', 'and', 'inventiveness', 'of', 'an', '-LCB-', 'offending', '-RCB-', 'country', \"'s\", 'own', 'citizens', '.', \"''\", 'No', 'price', 'for', 'the', 'new', 'shares', 'has', 'been', 'set', '*-23', '.', 'There', 'were', 'many', 'pioneer', 'PC', 'contributors', '.', 'The', 'new', 'company', 'said', '0', 'it', 'believes', '0', 'there', 'are', 'fewer', 'than', '100', 'potential', 'customers', 'for', 'supercomputers', 'priced', '*', 'between', '$', '15', 'million', 'and', '$', '30', 'million', '*U*', '--', 'presumably', 'the', 'Cray-3', 'price', 'range', '.', 'All', 'came', 'from', 'Cray', 'Research', '.', 'Japan', \"'s\", 'domestic', 'sales', 'of', 'cars', ',', 'trucks', 'and', 'buses', 'in', 'October', 'rose', '18', '%', 'from', 'a', 'year', 'earlier', 'to', '500,004', 'units', ',', 'a', 'record', 'for', 'the', 'month', ',', 'the', 'Japan', 'Automobile', 'Dealers', \"'\", 'Association', 'said', '0', '*T*-1', '.', 'When', 'demand', 'is', 'stronger', 'than', 'suppliers', 'can', 'handle', '*T*-1', 'and', 'delivery', 'times', 'lengthen', '*T*-1', ',', 'prices', 'tend', '*-2', 'to', 'rise', '.', '``', 'People', 'are', 'looking', '*-1', 'to', 'stake', 'their', 'claims', \"''\", 'now', 'before', 'the', 'number', 'of', 'available', 'nations', 'runs', 'out', ',', 'says', '*T*-2', 'Michael', 'Porter', ',', 'an', 'analyst', 'at', 'Smith', 'Barney', ',', 'Harris', 'Upham', '&', 'Co.', ',', 'New', 'York', '.', 'The', 'exact', 'amount', 'of', 'the', 'refund', 'will', 'be', 'determined', '*-16', 'next', 'year', 'based', 'on', 'actual', 'collections', 'made', '*', 'until', 'Dec.', '31', 'of', 'this', 'year', '.', 'Pro-forma', 'balance', 'sheets', 'clearly', 'show', 'why', 'Cray', 'Research', 'favored', 'the', 'spinoff', '*T*-1', '.', 'Saudi', 'Arabia', ',', 'for', 'its', 'part', ',', 'has', 'vowed', '*-2', 'to', 'enact', 'a', 'copyright', 'law', 'compatible', 'with', 'international', 'standards', 'and', '*-2', 'to', 'apply', 'the', 'law', 'to', 'computer', 'software', 'as', 'well', 'as', 'to', 'literary', 'works', ',', 'Mrs.', 'Hills', 'said', '0', '*T*-1', '.', 'The', 'move', 'leaves', 'United', 'Illuminating', 'Co.', 'and', 'Northeast', 'Utilities', 'as', 'the', 'remaining', 'outside', 'bidders', 'for', 'PS', 'of', 'New', 'Hampshire', ',', 'which', '*T*-1', 'also', 'has', 'proposed', 'an', 'internal', 'reorganization', 'plan', 'in', 'Chapter', '11', 'bankruptcy', 'proceedings', 'under', 'which', 'it', 'would', 'remain', 'an', 'independent', 'company', '*T*-2', '.', 'Commonwealth', 'Edison', 'said', '0', 'it', 'is', 'already', 'appealing', 'the', 'underlying', 'commission', 'order', 'and', 'is', 'considering', '*-1', 'appealing', 'Judge', 'Curry', \"'s\", 'order', '.', 'Separately', ',', 'the', 'Federal', 'Energy', 'Regulatory', 'Commission', 'turned', 'down', 'for', 'now', 'a', 'request', 'by', 'Northeast', 'seeking', 'approval', 'of', 'its', 'possible', 'purchase', 'of', 'PS', 'of', 'New', 'Hampshire', '.', 'The', 'documents', 'also', 'said', 'that', 'Cray', 'Computer', 'anticipates', '*-1', 'needing', 'perhaps', 'another', '$', '120', 'million', '*U*', 'in', 'financing', 'beginning', 'next', 'September', '.', 'In', '*-2', 'ending', 'Hungary', \"'s\", 'part', 'of', 'the', 'project', ',', 'Parliament', 'authorized', 'Prime', 'Minister', 'Miklos', 'Nemeth', 'to', 'modify', 'a', '1977', 'agreement', 'with', 'Czechoslovakia', ',', 'which', '*T*-64', 'still', 'wants', 'the', 'dam', 'to', 'be', 'built', '*-1', '.', 'Reserves', 'for', 'the', 'five', 'new', 'fields', 'total', '50', 'million', 'barrels', '.', 'Esso', 'Australia', 'Ltd.', ',', 'a', 'unit', 'of', 'New', 'York-based', 'Exxon', 'Corp.', ',', 'and', 'Broken', 'Hill', 'Pty.', 'operate', 'the', 'fields', 'in', 'a', 'joint', 'venture', '.', 'The', 'commission', 'is', 'expected', '*-1', 'to', 'rule', 'on', 'the', 'Braidwood', '2', 'case', 'by', 'year', 'end', '.', 'The', 'average', 'seven-day', 'simple', 'yield', 'of', 'the', '400', 'funds', 'was', '8.12', '%', ',', 'down', 'from', '8.14', '%', '.', 'Magna', 'said', '0', 'Mr.', 'McAlpine', 'resigned', '*-1', 'to', 'pursue', 'a', 'consulting', 'career', ',', 'with', 'Magna', 'as', 'one', 'of', 'his', 'clients', '.', 'Factory', 'shipments', 'fell', '1.6', '%', 'to', '$', '234.4', 'billion', '*U*', 'after', '*', 'rising', '5.4', '%', 'in', 'August', '.', 'In', 'July', ',', 'the', 'Environmental', 'Protection', 'Agency', 'imposed', 'a', 'gradual', 'ban', 'on', 'virtually', 'all', 'uses', 'of', 'asbestos', '.', 'Dennis', 'Hayes', 'and', 'Dale', 'Heatherington', ',', 'two', 'Atlanta', 'engineers', ',', 'were', 'co-developers', 'of', 'the', 'internal', 'modems', 'that', '*T*-33', 'allow', 'PCs', 'to', 'share', 'data', 'via', 'the', 'telephone', '.', 'The', 'White', 'House', 'said', '0', 'Mr.', 'Bush', 'decided', '*-1', 'to', 'grant', 'duty-free', 'status', 'for', '18', 'categories', ',', 'but', 'turned', 'down', 'such', 'treatment', 'for', 'other', 'types', 'of', 'watches', '``', 'because', 'of', 'the', 'potential', 'for', 'material', 'injury', 'to', 'watch', 'producers', 'located', '*', 'in', 'the', 'U.S.', 'and', 'the', 'Virgin', 'Islands', '.', \"''\", 'Mr.', 'Spoon', 'said', '0', 'the', 'plan', 'is', 'not', 'an', 'attempt', '*', 'to', 'shore', 'up', 'a', 'decline', 'in', 'ad', 'pages', 'in', 'the', 'first', 'nine', 'months', 'of', '1989', ';', 'Newsweek', \"'s\", 'ad', 'pages', 'totaled', '1,620', ',', 'a', 'drop', 'of', '3.2', '%', 'from', 'last', 'year', ',', 'according', 'to', 'Publishers', 'Information', 'Bureau', '.', 'We', \"'re\", 'talking', 'about', 'years', 'ago', 'before', 'anyone', 'heard', 'of', 'asbestos', 'having', 'any', 'questionable', 'properties', '.', 'This', 'is', 'Japan', '?', 'John', 'Rowe', ',', 'president', '*RNR*-1', 'and', 'chief', 'executive', 'officer', '*RNR*-1', 'of', 'New', 'England', 'Electric', ',', 'said', '0', 'the', 'company', \"'s\", 'return', 'on', 'equity', 'could', 'suffer', 'if', 'it', 'made', 'a', 'higher', 'bid', 'and', 'its', 'forecasts', 'related', '*', 'to', 'PS', 'of', 'New', 'Hampshire', '--', 'such', 'as', 'growth', 'in', 'electricity', 'demand', 'and', 'improved', 'operating', 'efficiencies', '--', 'did', \"n't\", 'come', 'true', '.', 'Analysts', 'noted', 'yesterday', 'that', 'Cray', 'Research', \"'s\", 'decision', '*', 'to', 'link', 'its', '$', '98.3', 'million', '*U*', 'promissory', 'note', 'to', 'Mr.', 'Cray', \"'s\", 'presence', 'will', 'complicate', 'a', 'valuation', 'of', 'the', 'new', 'company', '.', 'Shorter', 'maturities', 'are', 'considered', '*-9', 'a', 'sign', 'of', 'rising', 'rates', 'because', 'portfolio', 'managers', 'can', 'capture', 'higher', 'rates', 'sooner', '.', 'The', 'spinoff', 'also', 'will', 'compete', 'with', 'International', 'Business', 'Machines', 'Corp.', 'and', 'Japan', \"'s\", 'Big', 'Three', '--', 'Hitachi', 'Ltd.', ',', 'NEC', 'Corp.', 'and', 'Fujitsu', 'Ltd', '.', 'And', 'several', 'new', 'funds', 'that', '*T*-44', 'are', \"n't\", 'even', 'fully', 'invested', 'yet', 'have', 'jumped', '*-1', 'to', 'trade', 'at', 'big', 'premiums', '.', 'Documents', 'filed', '*', 'with', 'the', 'Securities', 'and', 'Exchange', 'Commission', 'on', 'the', 'pending', 'spinoff', 'disclosed', 'that', 'Cray', 'Research', 'Inc.', 'will', 'withdraw', 'the', 'almost', '$', '100', 'million', '*U*', 'in', 'financing', '0', 'it', 'is', 'providing', 'the', 'new', 'firm', '*T*-1', 'if', 'Mr.', 'Cray', 'leaves', 'or', 'if', 'the', 'product-design', 'project', '0', 'he', 'heads', '*T*-2', 'is', 'scrapped', '*-18', '.', 'If', 'the', 'debts', 'are', 'repaid', '*-49', ',', 'it', 'could', 'clear', 'the', 'way', '0', 'for', 'Soviet', 'bonds', 'to', 'be', 'sold', '*-50', 'in', 'the', 'U.S.', '*T*-1', '.', 'For', 'the', 'first', 'nine', 'months', 'of', 'the', 'year', ',', 'total', 'construction', 'spending', 'ran', 'about', '2', '%', 'above', 'last', 'year', \"'s\", 'level', '.', '``', 'Funny', 'Business', \"''\", '-LRB-', 'Soho', ',', '228', 'pages', ',', '$', '17.95', '*U*', '-RRB-', 'by', 'Gary', 'Katzenstein', 'is', 'anything', 'but', '*?*', '.', 'He', 'said', 'that', 'for', 'the', 'second', 'month', 'in', 'a', 'row', ',', 'food', 'processors', 'reported', 'a', 'shortage', 'of', 'nonfat', 'dry', 'milk', '.', 'They', 'will', 'remain', 'on', 'a', 'lower-priority', 'list', 'that', '*T*-27', 'includes', '17', 'other', 'countries', '.', 'In', 'its', 'construction', 'spending', 'report', ',', 'the', 'Commerce', 'Department', 'said', '0', 'residential', 'construction', ',', 'which', '*T*-50', 'accounts', 'for', 'nearly', 'half', 'of', 'all', 'construction', 'spending', ',', 'was', 'off', '0.9', '%', '*ICH*-3', 'in', 'September', 'to', 'an', 'annual', 'rate', 'of', '$', '191.9', 'billion', '*U*', '.', 'When', 'it', \"'s\", 'time', 'for', 'their', 'biannual', 'powwow', '*T*-1', ',', 'the', 'nation', \"'s\", 'manufacturing', 'titans', 'typically', 'jet', 'off', 'to', 'the', 'sunny', 'confines', 'of', 'resort', 'towns', 'like', 'Boca', 'Raton', 'and', 'Hot', 'Springs', '.', 'He', 'said', '0', 'Mexico', 'could', 'be', 'one', 'of', 'the', 'next', 'countries', '0', '*T*-1', 'to', 'be', 'removed', '*-2', 'from', 'the', 'priority', 'list', 'because', 'of', 'its', 'efforts', '*', 'to', 'craft', 'a', 'new', 'patent', 'law', '.', 'The', 'U.S.', ',', '*-1', 'claiming', 'some', 'success', 'in', 'its', 'trade', 'diplomacy', ',', 'removed', 'South', 'Korea', ',', 'Taiwan', 'and', 'Saudi', 'Arabia', 'from', 'a', 'list', 'of', 'countries', '0', 'it', 'is', 'closely', 'watching', '*T*-2', 'for', '*', 'allegedly', 'failing', '*-3', 'to', 'honor', 'U.S.', 'patents', ',', 'copyrights', 'and', 'other', 'intellectual-property', 'rights', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3YFF8388MKW",
        "outputId": "dd37bbae-794c-46ca-dd73-51daa8118688"
      },
      "source": [
        "start = time.time()\n",
        "model_predicted_output = Viterbi(test_untagged_words)\n",
        "end = time.time()\n",
        "difference = end-start\n",
        " \n",
        "print(\"Time taken in seconds: \", difference)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken in seconds:  44.29931950569153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhsT1KGx9TN_"
      },
      "source": [
        "# accuracy\n",
        "check = [i for i, j in zip(test_tagged_words, model_predicted_output) if i == j] "
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOp0WcRO-ROe",
        "outputId": "f3447d67-a989-4e83-daac-a7a3cb116d66"
      },
      "source": [
        "len(check) # checcking lenth of all corrected tagged words\n",
        "len(model_predicted_output) # checking length of all model_output"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2653"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jRxaRamNz8q",
        "outputId": "19e47641-1cec-4095-ea16-b0ccb3996cee"
      },
      "source": [
        "accuracy = len(check)/len(model_predicted_output)\n",
        "print('Viterbi Algorithm Accuracy: ',accuracy*100)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Viterbi Algorithm Accuracy:  79.41952506596306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpEXF2fgJ_VF"
      },
      "source": [
        "#modified Viterbi to include rule based tagger in it\n",
        "def Viterbi_rule_based(words, train_bag = train_tagged_words):\n",
        "    state = []\n",
        "    T = list(set([pair[1] for pair in train_bag]))\n",
        "     \n",
        "    for key, word in enumerate(words):\n",
        "        #initialise list of probability column for a given observation\n",
        "        p = [] \n",
        "        for tag in T:\n",
        "            if key == 0:\n",
        "                transition_p = tags_df.loc['.', tag]\n",
        "            else:\n",
        "                transition_p = tags_df.loc[state[-1], tag]\n",
        "                 \n",
        "            # compute emission and state probabilities\n",
        "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
        "            state_probability = emission_p * transition_p    \n",
        "            p.append(state_probability)\n",
        "             \n",
        "        pmax = max(p)\n",
        "        state_max = rule_based_tagger.tag([word])[0][1]\n",
        "        if(pmax==0):\n",
        "            state_max = rule_based_tagger.tag([word])[0][1] # assign based on rule based tagger\n",
        "        else:\n",
        "            if state_max != 'X':\n",
        "                # getting state for which probability is maximum\n",
        "                state_max = T[p.index(pmax)]                \n",
        "             \n",
        "         \n",
        "        state.append(state_max)\n",
        "    return list(zip(words, state))      "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4SAaSNGKPlF",
        "outputId": "469ab4cf-7a8f-41b7-8de3-3476a42a81ad"
      },
      "source": [
        "#test accuracy on subset of test data \n",
        "start = time.time()\n",
        "tagged_seq = Viterbi_rule_based(test_untagged_words)\n",
        "end = time.time()\n",
        "difference = end-start\n",
        " \n",
        "print(\"Time taken in seconds: \", difference)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken in seconds:  44.171035051345825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJX6jSC4KTbf"
      },
      "source": [
        "# accuracy\n",
        "check = [i for i, j in zip(tagged_seq, test_tagged_words) if i == j] "
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAc1XQZTLTq7",
        "outputId": "44f649ec-519a-4c92-f719-a623bc755a42"
      },
      "source": [
        "accuracy = len(check)/len(tagged_seq)\n",
        "accuracy\n",
        "#print('Viterbi Algorithm Accuracy: ',accuracy*100)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9189596683000377"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObMcsaKRvy11"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}